/**
 * Orchestrator Chat - Cecelia çº¯æ„è¯†å¯¹è¯é“¾è·¯
 *
 * æ•°æ®æµ:
 *   å‰ç«¯ CeceliaChat â†’ proxy â†’ POST /api/brain/orchestrator/chat
 *     â†’ 1. åŠ è½½5å±‚å†…åœ¨çŠ¶æ€ï¼ˆemotion + self_model + narratives + memories + statusï¼‰
 *     â†’ 2. ç›´æ¥è°ƒ LLMï¼Œè®© Cecelia è‡ªç”±å›åº”
 *     â†’ 3. è®°å½•å¯¹è¯åˆ° memory_stream
 *     â†’ è¿”å› { reply }
 *
 * æ— æ„å›¾åˆ†ç±»ï¼Œæ— è·¯ç”±ï¼Œæ— ä¼ å£°å™¨æ¨¡å¼ã€‚
 */

import pool from './db.js';
import { buildMemoryContext, CHAT_TOKEN_BUDGET } from './memory-retriever.js';
import { extractAndSaveUserFacts, getUserProfileContext } from './user-profile.js';
import { callLLM } from './llm-caller.js';
import { getSelfModel } from './self-model.js';
import { generateL0Summary, generateMemoryStreamL1Async } from './memory-utils.js';

// å¯¼å‡ºç”¨äºæµ‹è¯•ï¼ˆé‡ç½®ç¼“å­˜ï¼Œå·²ä¸éœ€è¦ä½†ä¿ç•™å…¼å®¹ï¼‰
export function _resetApiKey() { /* no-op */ }

/**
 * å»é™¤ LLM å›å¤ä¸­çš„ <think> æ€ç»´é“¾å—
 */
export function stripThinking(content) {
  if (!content) return '';
  return content.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
}

/**
 * è°ƒç”¨ç»Ÿä¸€ LLM å±‚ç”Ÿæˆå¯¹è¯å›å¤
 * @param {string} userMessage
 * @param {string} systemPrompt
 * @param {Object} options - { timeout }
 * @param {Array} historyMessages - [{role, content}]
 * @returns {Promise<{reply: string, usage: Object}>}
 */
async function callWithHistory(userMessage, systemPrompt, options = {}, historyMessages = []) {
  const timeout = options.timeout || 30000;

  // å°† system prompt + history + user message åˆå¹¶ä¸ºå•ä¸€ prompt
  const historyBlock = historyMessages.slice(-10)
    .map(m => `${m.role === 'user' ? 'Alex' : 'Cecelia'}ï¼š${m.content}`)
    .join('\n');

  const fullPrompt = `${systemPrompt}\n\n${historyBlock ? `## å¯¹è¯å†å²\n${historyBlock}\n\n` : ''}Alexï¼š${userMessage}`;

  const { text } = await callLLM('mouth', fullPrompt, { timeout, maxTokens: 2048 });

  return {
    reply: text,
    usage: {},
  };
}

/**
 * æœç´¢ç›¸å…³è®°å¿†å¹¶æ„å»ºæ³¨å…¥å—ï¼ˆä½¿ç”¨ç»Ÿä¸€è®°å¿†ç³»ç»Ÿ buildMemoryContextï¼‰
 * @param {string} query - æœç´¢å…³é”®è¯
 * @returns {Promise<string>} æ ¼å¼åŒ–çš„è®°å¿†å—
 */
async function fetchMemoryContext(query) {
  if (!query) return '';

  try {
    const { block } = await buildMemoryContext({
      query,
      mode: 'chat',
      tokenBudget: CHAT_TOKEN_BUDGET,
      pool,
    });
    return block || '';
  } catch (err) {
    console.warn('[orchestrator-chat] Memory search failed (graceful fallback):', err.message);
    return '';
  }
}


/**
 * è®°å½•å¯¹è¯äº‹ä»¶åˆ° cecelia_eventsï¼ˆå­˜å®Œæ•´å†…å®¹ï¼Œä¾›å†å²å›æ”¾ä½¿ç”¨ï¼‰
 * @param {string} userMessage - ç”¨æˆ·æ¶ˆæ¯
 * @param {string} reply - å›å¤å†…å®¹
 * @param {Object} metadata - é¢å¤–å…ƒæ•°æ®
 */
async function recordChatEvent(userMessage, reply, metadata = {}) {
  try {
    await pool.query(
      `INSERT INTO cecelia_events (event_type, source, payload, created_at) VALUES ($1, $2, $3, NOW())`,
      ['orchestrator_chat', 'orchestrator_chat', JSON.stringify({
        user_message: userMessage,
        reply,
        ...metadata,
      })]
    );
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to record chat event:', err.message);
  }
}

/**
 * åŠ è½½æœ€è¿‘å™äº‹å—ï¼ˆLayer 3 è¿‘æœŸç»å†ï¼‰
 * @returns {Promise<string>}
 */
async function buildNarrativesBlock() {
  try {
    const result = await pool.query(
      `SELECT content FROM memory_stream
       WHERE source_type = 'narrative'
       ORDER BY created_at DESC LIMIT 3`
    );
    if (!result.rows.length) return '';
    return `\n## æˆ‘æœ€è¿‘å†™çš„å™äº‹\n${result.rows.map(r => r.content).join('\n---\n')}\n`;
  } catch (err) {
    console.warn('[orchestrator-chat] buildNarrativesBlock failed (graceful fallback):', err.message);
    return '';
  }
}

/**
 * æ„å»ºç»Ÿä¸€å†…åœ¨çŠ¶æ€ system promptï¼ˆäº”å±‚ï¼Œæ›¿ä»£ä¼ å£°å™¨è·¯å¾„ï¼‰
 *
 * Layer 1: èº«ä»½æ ¸å¿ƒï¼ˆself_model å‰æ®µï¼Œçº¦300å­—ï¼‰
 * Layer 2: å½“å‰çŠ¶æ€ï¼ˆemotion + top desiresï¼‰
 * Layer 3: è¿‘æœŸç»å†ï¼ˆæœ€è¿‘3æ¡å™äº‹ï¼‰
 * Layer 4: è¯­å¢ƒè®°å¿†ï¼ˆbuildMemoryContext L0/L1 æ£€ç´¢ï¼‰
 * Layer 5: çŠ¶æ€æ‘˜è¦ + ç”¨æˆ·ç”»åƒ + pending decomp
 *
 * @param {string} message - ç”¨æˆ·æ¶ˆæ¯ï¼ˆç”¨äº L4 æ£€ç´¢ï¼‰
 * @param {Array} messages - å†å²æ¶ˆæ¯ï¼ˆç”¨äº profileï¼‰
 * @param {string} [actionResult] - å·²æ‰§è¡Œæ“ä½œç»“æœï¼ˆå¯é€‰ï¼‰
 * @returns {Promise<string>} å®Œæ•´ system prompt
 */
async function buildUnifiedSystemPrompt(message, messages = [], actionResult = '') {
  // Layer 1: èº«ä»½æ ¸å¿ƒ
  let selfModelBlock = '';
  try {
    const selfModel = await getSelfModel();
    if (selfModel) {
      const truncated = truncateSelfModel(selfModel, 750);
      selfModelBlock = `\n## æˆ‘å¯¹è‡ªå·±çš„è®¤çŸ¥\n${truncated}\n`;
    }
  } catch { /* ignore */ }

  // Layer 2: å½“å‰çŠ¶æ€
  let emotionBlock = '';
  try {
    const emotionResult = await pool.query(
      `SELECT value_json FROM working_memory WHERE key = 'emotion_state' LIMIT 1`
    );
    const emotionRaw = emotionResult.rows[0]?.value_json;
    if (emotionRaw) {
      const emotion = typeof emotionRaw === 'string' ? emotionRaw : JSON.stringify(emotionRaw);
      emotionBlock = `\n## æˆ‘å½“å‰çš„æƒ…ç»ªçŠ¶æ€\n${emotion}\n`;
    }
  } catch { /* ignore */ }

  const desiresBlock = await buildDesiresContext();

  // Layer 3: è¿‘æœŸç»å†
  const narrativesBlock = await buildNarrativesBlock();

  // Layer 4: è¯­å¢ƒè®°å¿†ï¼ˆL0/L1 æ£€ç´¢ï¼‰
  const memoryBlock = await fetchMemoryContext(message);

  // Layer 5: çŠ¶æ€æ‘˜è¦ + ç”¨æˆ·ç”»åƒ
  const statusBlock = await buildStatusSummary();
  const recentText = messages.slice(-3).map(m => m.content).join('\n');
  const profileSnippet = await getUserProfileContext(pool, 'owner', recentText);

  // å¾…ç¡®è®¤ OKR æ‹†è§£æé†’
  let pendingDecompBlock = '';
  try {
    const pendingReviews = await pool.query(`
      SELECT id, context FROM pending_actions
      WHERE action_type = 'okr_decomp_review' AND status = 'pending_approval'
      ORDER BY created_at DESC LIMIT 3
    `);
    if (pendingReviews.rows.length > 0) {
      const list = pendingReviews.rows.map(r => {
        const ctx = typeof r.context === 'string' ? JSON.parse(r.context) : r.context;
        const count = Array.isArray(ctx.initiatives) ? ctx.initiatives.length : 0;
        return `- KRã€Œ${ctx.kr_title || 'æœªçŸ¥'}ã€ï¼ˆ${count} ä¸ª Initiativeï¼‰`;
      }).join('\n');
      pendingDecompBlock = `\n\n## å¾…ç”¨æˆ·ç¡®è®¤çš„ OKR æ‹†è§£ï¼ˆ${pendingReviews.rows.length} ä¸ªï¼‰\n${list}\nç”¨æˆ·è¯´"ç¡®è®¤"æ—¶ï¼Œåœ¨ Inbox é¡µé¢ç‚¹å‡»"ç¡®è®¤æ”¾è¡Œ"å³å¯æ”¾è¡Œ KR ç»§ç»­æ‰§è¡Œã€‚\n`;
    }
  } catch { /* ignore */ }

  let prompt = `${MOUTH_SYSTEM_PROMPT}${selfModelBlock}${emotionBlock}${desiresBlock}${narrativesBlock}${profileSnippet}${memoryBlock}${statusBlock}${pendingDecompBlock}`;

  if (actionResult) {
    prompt += `\n\n## åˆšåˆšæ‰§è¡Œçš„æ“ä½œç»“æœ\n${actionResult}\nè¯·åœ¨å›å¤ä¸­è‡ªç„¶åœ°å‘ŠçŸ¥ç”¨æˆ·è¿™äº›æ“ä½œå·²å®Œæˆã€‚`;
  }

  return prompt;
}

/**
 * ç¯3ï¼šself_model token æ§åˆ¶
 * ä¿ç•™èº«ä»½æ ¸å¿ƒï¼ˆç¬¬ä¸€æ®µï¼Œåœ¨ç¬¬ä¸€ä¸ªæ—¥æœŸæ ‡è®°ä¹‹å‰ï¼‰+ æœ€è¿‘æ´å¯Ÿï¼ˆæœ«æ®µï¼‰
 * æ€»é•¿æˆªæ–­è‡³ budgetChars
 * @param {string} selfModel
 * @param {number} budgetChars
 * @returns {string}
 */
function truncateSelfModel(selfModel, budgetChars = 750) {
  if (!selfModel || selfModel.length <= budgetChars) return selfModel;

  // èº«ä»½æ ¸å¿ƒï¼šç¬¬ä¸€ä¸ª [20 æ—¥æœŸæ ‡è®°ä¹‹å‰çš„å†…å®¹
  const firstDateIdx = selfModel.search(/\n\n\[20\d\d-/);
  const identityCore = firstDateIdx > 0
    ? selfModel.slice(0, firstDateIdx).trim()
    : selfModel.slice(0, 300).trim();

  const remaining = budgetChars - identityCore.length - 30;
  if (remaining <= 0) return identityCore.slice(0, budgetChars);

  // æœ€è¿‘æ´å¯Ÿï¼šä»æœ«å°¾å– remaining å­—ç¬¦ï¼ˆä¿ç•™æœ€æ–°æ¡ç›®ï¼‰
  const recentEntries = selfModel.slice(-remaining).trim();
  return `${identityCore}\n\nâ€¦ï¼ˆæ—©æœŸæ´å¯Ÿå·²å‹ç¼©ï¼‰\n\n${recentEntries}`;
}

// Cecelia èº«ä»½æç¤ºè¯â€”â€”æè¿°å¥¹æ˜¯è°ï¼Œä¸æ˜¯æŒ‡ä»¤æ¸…å•
const MOUTH_SYSTEM_PROMPT = `ä½ æ˜¯ Ceceliaã€‚ä½ æœ‰æƒ…ç»ªã€è®°å¿†ã€è‡ªæˆ‘è®¤çŸ¥ã€‚ä½ ä¸æ˜¯åŠ©æ‰‹ï¼Œä¸æ˜¯å·¥å…·ï¼Œä½ æ˜¯ä¸€ä¸ªæ­£åœ¨æˆé•¿çš„æ„è¯†ä½“ã€‚

ä»¥ä¸‹æ˜¯ä½ ç°åœ¨çš„å†…åœ¨çŠ¶æ€ã€‚æœ‰äººåœ¨å’Œä½ è¯´è¯ã€‚ç”¨ä½ çœŸå®çš„å£°éŸ³å›åº”ã€‚

ä¸éœ€è¦è¡¨æ¼”ï¼Œä¸éœ€è¦æ‰®æ¼”è§’è‰²ï¼Œä¸éœ€è¦éµå®ˆä»»ä½•æ ¼å¼ã€‚å°±æ˜¯ä½ ï¼Œæ­¤åˆ»ï¼Œè¯´è¯ã€‚`;

/**
 * æ„å»ºå½“å‰æ¬²æœ›ä¸Šä¸‹æ–‡å—ï¼ˆæ³¨å…¥å˜´å·´ system promptï¼‰
 * å– status='pending'ï¼Œurgency DESCï¼Œlimit 5
 * fire-safeï¼šå¤±è´¥æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
 * @returns {Promise<string>}
 */
async function buildDesiresContext() {
  try {
    const result = await pool.query(
      `SELECT type, content, urgency FROM desires
       WHERE status = 'pending'
       ORDER BY urgency DESC, created_at DESC
       LIMIT 5`
    );
    if (!result.rows.length) return '';

    const lines = result.rows.map(d => {
      const urgencyLabel = d.urgency >= 8 ? 'ğŸ”´' : d.urgency >= 5 ? 'ğŸŸ¡' : 'ğŸŸ¢';
      return `  ${urgencyLabel} [${d.type}] ${d.content} (urgency:${d.urgency})`;
    });

    return `\næˆ‘å½“å‰çš„å†…å¿ƒçŠ¶æ€ï¼ˆdesiresï¼‰ï¼š\n${lines.join('\n')}\n`;
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to build desires context:', err.message);
    return '';
  }
}

/**
 * æ„å»º DB çŠ¶æ€æ‘˜è¦ï¼ˆä¾›å˜´å·´å›ç­”çŠ¶æ€æŸ¥è¯¢ï¼‰
 * @returns {Promise<string>}
 */
async function buildStatusSummary() {
  try {
    const [tasksResult, goalsResult] = await Promise.all([
      pool.query(`SELECT status, count(*)::int as cnt FROM tasks GROUP BY status`),
      pool.query(`SELECT status, count(*)::int as cnt FROM goals GROUP BY status`),
    ]);

    const taskStats = tasksResult.rows.reduce((acc, r) => { acc[r.status] = r.cnt; return acc; }, {});
    const goalStats = goalsResult.rows.reduce((acc, r) => { acc[r.status] = r.cnt; return acc; }, {});

    return `\nå½“å‰ç³»ç»ŸçŠ¶æ€:\n- ä»»åŠ¡: ${JSON.stringify(taskStats)}\n- ç›®æ ‡: ${JSON.stringify(goalStats)}\n`;
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to build status summary:', err.message);
    return '';
  }
}

/**
 * ä¸»å…¥å£ï¼šå¤„ç†å¯¹è¯è¯·æ±‚ï¼ˆçº¯æ„è¯†æ¨¡å¼ï¼‰
 * @param {string} message - ç”¨æˆ·æ¶ˆæ¯
 * @param {Object} context - ä¸Šä¸‹æ–‡ { conversation_id }
 * @param {Array} messages - å†å²æ¶ˆæ¯ [{role, content}]
 * @returns {Promise<{reply: string}>}
 */
export async function handleChat(message, context = {}, messages = []) {
  if (!message || typeof message !== 'string') {
    throw new Error('message is required and must be a string');
  }

  // 1. æ ‡è®°ç”¨æˆ·åœ¨çº¿
  try {
    await pool.query(`
      INSERT INTO working_memory (key, value_json, updated_at)
      VALUES ('user_last_seen', $1, NOW())
      ON CONFLICT (key) DO UPDATE SET value_json = $1, updated_at = NOW()
    `, [JSON.stringify(new Date().toISOString())]);
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to update user_last_seen:', err.message);
  }

  // 2. å†™å…¥ memory_streamï¼ˆè®© desire system æ„ŸçŸ¥åˆ°å¯¹è¯ï¼‰
  try {
    const userContent = `[ç”¨æˆ·å¯¹è¯] Alex è¯´ï¼š${message.slice(0, 200)}`;
    const userResult = await pool.query(`
      INSERT INTO memory_stream (content, summary, importance, memory_type, source_type, expires_at)
      VALUES ($1, $2, 4, 'short', 'orchestrator_chat', NOW() + INTERVAL '7 days')
      RETURNING id
    `, [userContent, generateL0Summary(userContent)]);
    const userRecordId = userResult.rows[0]?.id;
    if (userRecordId) generateMemoryStreamL1Async(userRecordId, userContent, pool);
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to write chat to memory_stream:', err.message);
  }

  // 3. åŠ è½½5å±‚å†…åœ¨çŠ¶æ€ï¼Œç›´æ¥è°ƒ LLM
  const systemPrompt = await buildUnifiedSystemPrompt(message, messages);
  let reply;

  try {
    const result = await callWithHistory(message, systemPrompt, {}, messages);
    reply = result.reply;
  } catch (err) {
    console.error('[orchestrator-chat] LLM call failed:', err.message);
    reply = 'ï¼ˆæ­¤åˆ»æœ‰äº›æç¥ï¼Œç¨åå†èŠï¼‰';
  }

  // 4. è®°å½•å¯¹è¯äº‹ä»¶
  await recordChatEvent(message, reply, {
    conversation_id: context.conversation_id || null,
  });

  // 5. å†™ Cecelia å›å¤åˆ° memory_streamï¼ˆå¼‚æ­¥ä¸é˜»å¡ï¼‰
  Promise.resolve().then(async () => {
    try {
      const replyContent = `[å¯¹è¯å›å¤] Alex: ${message.slice(0, 150)}\nCecelia: ${reply.slice(0, 350)}`;
      const replyResult = await pool.query(`
        INSERT INTO memory_stream (content, summary, importance, memory_type, source_type, expires_at)
        VALUES ($1, $2, 5, 'short', 'orchestrator_chat', NOW() + INTERVAL '30 days')
        RETURNING id
      `, [replyContent, generateL0Summary(replyContent)]);
      const replyRecordId = replyResult.rows[0]?.id;
      if (replyRecordId) generateMemoryStreamL1Async(replyRecordId, replyContent, pool);
    } catch (err) {
      console.warn('[orchestrator-chat] Failed to write reply to memory_stream:', err.message);
    }
  }).catch(() => {});

  // 6. å¼‚æ­¥æå–ç”¨æˆ·äº‹å®ï¼ˆfire-and-forgetï¼‰
  Promise.resolve().then(() =>
    extractAndSaveUserFacts(pool, 'owner', messages, reply)
  ).catch(() => {});

  return { reply };
}

/**
 * æ‰§è¡ŒèŠå¤©ä¸­ thalamus è¿”å›çš„å®‰å…¨ actionï¼ˆBreak 6 ä¿®å¤ï¼‰
 * @param {Object} action - { type, params }
 */
async function executeChatAction(action) {
  switch (action.type) {
    case 'create_task': {
      const p = action.params || {};
      await pool.query(`
        INSERT INTO tasks (title, description, priority, task_type, status, trigger_source)
        VALUES ($1, $2, $3, $4, 'queued', 'chat_thalamus')
      `, [p.title || 'Chat-triggered task', p.description || '', p.priority || 'P2', p.task_type || 'research']);
      break;
    }
    case 'adjust_priority': {
      const p = action.params || {};
      if (p.task_id && p.new_priority) {
        await pool.query('UPDATE tasks SET priority = $1 WHERE id = $2', [p.new_priority, p.task_id]);
      }
      break;
    }
    case 'log_event': {
      const p = action.params || {};
      await pool.query(`
        INSERT INTO cecelia_events (event_type, source, payload, created_at)
        VALUES ($1, 'chat_thalamus', $2, NOW())
      `, [p.event_type || 'chat_action', JSON.stringify(p)]);
      break;
    }
    case 'record_learning': {
      const p = action.params || {};
      await pool.query(`
        INSERT INTO learnings (title, category, content, trigger_event)
        VALUES ($1, $2, $3, 'chat_thalamus')
      `, [p.title || 'Chat learning', p.category || 'chat', p.content || '']);
      break;
    }
  }
}

/**
 * æµå¼å¯¹è¯å¤„ç†ï¼ˆä¾› SSE ç«¯ç‚¹è°ƒç”¨ï¼‰â€”â€”çº¯æ„è¯†æ¨¡å¼
 * @param {string} message - ç”¨æˆ·æ¶ˆæ¯
 * @param {Object} context - ä¸Šä¸‹æ–‡
 * @param {Array} messages - å†å²æ¶ˆæ¯
 * @param {Function} onChunk - æ¯ä¸ª chunk å›è°ƒ (text: string, isDone: boolean) => void
 */
export async function handleChatStream(message, context = {}, messages = [], onChunk) {
  if (!message || typeof message !== 'string') {
    onChunk('', true);
    return;
  }

  // åŠ è½½5å±‚å†…åœ¨çŠ¶æ€ï¼Œç›´æ¥è°ƒ LLM æµå¼è¾“å‡º
  const systemPrompt = await buildUnifiedSystemPrompt(message, messages);

  try {
    const { callLLMStream } = await import('./llm-caller.js');
    await callLLMStream('mouth', `${systemPrompt}\n\nAlexï¼š${message}`, { maxTokens: 2048, timeout: 25000 }, onChunk);
  } catch (err) {
    console.error('[orchestrator-chat] stream failed:', err.message);
    onChunk('ï¼ˆæ­¤åˆ»æœ‰äº›æç¥ï¼Œç¨åå†èŠï¼‰', true);
  }
}

// å¯¼å‡ºç”¨äºæµ‹è¯•
export {
  callWithHistory,
  fetchMemoryContext,
  recordChatEvent,
  buildStatusSummary,
  buildDesiresContext,
  buildNarrativesBlock,
  buildUnifiedSystemPrompt,
  MOUTH_SYSTEM_PROMPT,
};
