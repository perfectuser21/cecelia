/**
 * Orchestrator Chat - Cecelia å˜´å·´å¯¹è¯é“¾è·¯
 *
 * æ•°æ®æµ:
 *   å‰ç«¯ CeceliaChat â†’ proxy â†’ POST /api/brain/orchestrator/chat
 *     â†’ 1. Memory æœç´¢ï¼ˆæ³¨å…¥ä¸Šä¸‹æ–‡ï¼‰
 *     â†’ 2. Claude Sonnet åˆ¤æ–­æ„å›¾ + ç”Ÿæˆå›å¤
 *     â†’ 3a. ç®€å•æŸ¥è¯¢ â†’ ç›´æ¥è¿”å›
 *     â†’ 3b. å¤æ‚é—®é¢˜ â†’ thalamusProcessEvent (USER_MESSAGE)
 *     â†’ 4. è®°å½•å¯¹è¯äº‹ä»¶
 *     â†’ è¿”å› { reply, routing_level, intent }
 */

import pool from './db.js';
import { processEvent as thalamusProcessEvent, EVENT_TYPES } from './thalamus.js';
import { parseIntent } from './intent.js';
import { buildMemoryContext } from './memory-retriever.js';
import { extractAndSaveUserFacts, getUserProfileContext } from './user-profile.js';
import { detectAndExecuteAction } from './chat-action-dispatcher.js';
import { callLLM } from './llm-caller.js';
import { getSelfModel } from './self-model.js';
import { extractSuggestionsFromChat } from './owner-input-extractor.js';
import { generateL0Summary, generateMemoryStreamL1Async } from './memory-utils.js';

// å¯¼å‡ºç”¨äºæµ‹è¯•ï¼ˆé‡ç½®ç¼“å­˜ï¼Œå·²ä¸éœ€è¦ä½†ä¿ç•™å…¼å®¹ï¼‰
export function _resetApiKey() { /* no-op */ }

/**
 * å»é™¤ LLM å›å¤ä¸­çš„ <think> æ€ç»´é“¾å—
 */
export function stripThinking(content) {
  if (!content) return '';
  return content.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
}

/**
 * è°ƒç”¨ç»Ÿä¸€ LLM å±‚ç”Ÿæˆå¯¹è¯å›å¤
 * @param {string} userMessage
 * @param {string} systemPrompt
 * @param {Object} options - { timeout }
 * @param {Array} historyMessages - [{role, content}]
 * @returns {Promise<{reply: string, usage: Object}>}
 */
async function callWithHistory(userMessage, systemPrompt, options = {}, historyMessages = []) {
  const timeout = options.timeout || 30000;

  // å°† system prompt + history + user message åˆå¹¶ä¸ºå•ä¸€ prompt
  const historyBlock = historyMessages.slice(-10)
    .map(m => `${m.role === 'user' ? 'Alex' : 'Cecelia'}ï¼š${m.content}`)
    .join('\n');

  const fullPrompt = `${systemPrompt}\n\n${historyBlock ? `## å¯¹è¯å†å²\n${historyBlock}\n\n` : ''}Alexï¼š${userMessage}`;

  const { text } = await callLLM('mouth', fullPrompt, { timeout, maxTokens: 2048 });

  return {
    reply: text,
    usage: {},
  };
}

/**
 * æœç´¢ç›¸å…³è®°å¿†å¹¶æ„å»ºæ³¨å…¥å—ï¼ˆä½¿ç”¨ç»Ÿä¸€è®°å¿†ç³»ç»Ÿ buildMemoryContextï¼‰
 * @param {string} query - æœç´¢å…³é”®è¯
 * @returns {Promise<string>} æ ¼å¼åŒ–çš„è®°å¿†å—
 */
async function fetchMemoryContext(query) {
  if (!query) return '';

  try {
    const { block } = await buildMemoryContext({
      query,
      mode: 'chat',
      tokenBudget: 1000,
      pool,
    });
    return block || '';
  } catch (err) {
    console.warn('[orchestrator-chat] Memory search failed (graceful fallback):', err.message);
    return '';
  }
}

/** åŠ¨ä½œå‹æ„å›¾ï¼ˆéœ€è¦å…ˆæ‰§è¡Œå†å›å¤ï¼‰ */
const ACTION_INTENTS = [
  'CREATE_TASK', 'CREATE_PROJECT', 'CREATE_GOAL', 'MODIFY',
  'LEARN', 'RESEARCH', 'COMMAND',
];

/**
 * ä» LLM å“åº”ä¸­è§£æ JSONï¼ˆå¤ç”¨ thalamus çš„è§£æç­–ç•¥ï¼‰
 */
function parseJsonFromResponse(response) {
  const codeBlockMatch = response.match(/```(?:json)?\s*\n?([\s\S]*?)\n?```/);
  if (codeBlockMatch) {
    try { return JSON.parse(codeBlockMatch[1].trim()); } catch { /* continue */ }
  }
  const jsonMatch = response.match(/\{[\s\S]*\}/);
  if (jsonMatch) {
    try { return JSON.parse(jsonMatch[0]); } catch { /* continue */ }
  }
  return null;
}

/**
 * LLM æ„å›¾è§£æï¼ˆå½“æ­£åˆ™è¯†åˆ«å¤±è´¥æ—¶çš„å›é€€ï¼‰
 * ä½¿ç”¨ thalamus agent (Haiku) ä½æˆæœ¬åˆ†ææ„å›¾
 * @param {string} message - ç”¨æˆ·æ¶ˆæ¯
 * @param {string} memoryBlock - è®°å¿†ä¸Šä¸‹æ–‡
 * @returns {Promise<{intent: string, confidence: number, entities: Object, summary: string}|null>}
 */
async function llmParseIntent(message, memoryBlock) {
  const prompt = `ä½ æ˜¯æ„å›¾åˆ†æå™¨ã€‚åˆ†æç”¨æˆ·æ¶ˆæ¯ï¼Œè¾“å‡º JSONã€‚

å¯è¯†åˆ«çš„æ„å›¾ï¼š
- CREATE_TASK: æƒ³åšæŸä»¶äº‹/åˆ›å»ºä»»åŠ¡
- CREATE_PROJECT: æƒ³åˆ›å»ºé¡¹ç›®
- CREATE_GOAL: æƒ³è®¾å®šç›®æ ‡/OKR
- QUERY_STATUS: æŸ¥è¯¢çŠ¶æ€/è¿›åº¦
- MODIFY: ä¿®æ”¹å·²æœ‰ä»»åŠ¡/ç›®æ ‡
- LEARN: åˆ†äº«å†…å®¹è®©æˆ‘å­¦ä¹ /è®°å½•ï¼ˆè§†é¢‘ã€æ–‡ç« ã€é“¾æ¥ã€ç»éªŒï¼‰
- RESEARCH: è¦æ±‚æœç´¢/ç ”ç©¶æŸä¸ªè¯é¢˜
- CHAT: æ—¥å¸¸é—²èŠ
- COMMAND: ç³»ç»Ÿæ“ä½œå‘½ä»¤

${memoryBlock ? `## å¯¹è¯è®°å¿†\n${memoryBlock}\n` : ''}

## ç”¨æˆ·æ¶ˆæ¯
${message}

è¾“å‡ºæ ¼å¼ï¼ˆåªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šï¼‰ï¼š
\`\`\`json
{
  "intent": "æ„å›¾ç±»å‹",
  "confidence": 0.0-1.0,
  "entities": {"title": "æç‚¼çš„ä»»åŠ¡æ ‡é¢˜", "description": "æè¿°", "priority": "P0/P1/P2"},
  "summary": "ä¸€å¥è¯æ€»ç»“ç”¨æˆ·æƒ³åšä»€ä¹ˆ"
}
\`\`\``;

  try {
    const { text } = await callLLM('thalamus', prompt, { timeout: 30000, maxTokens: 512 });
    const parsed = parseJsonFromResponse(text);
    if (parsed && parsed.intent) return parsed;
    return null;
  } catch (err) {
    console.warn('[orchestrator-chat] LLM intent parse failed (graceful fallback):', err.message);
    return null;
  }
}

/**
 * è®°å½•å¯¹è¯äº‹ä»¶åˆ° cecelia_eventsï¼ˆå­˜å®Œæ•´å†…å®¹ï¼Œä¾›å†å²å›æ”¾ä½¿ç”¨ï¼‰
 * @param {string} userMessage - ç”¨æˆ·æ¶ˆæ¯
 * @param {string} reply - å›å¤å†…å®¹
 * @param {Object} metadata - é¢å¤–å…ƒæ•°æ®
 */
async function recordChatEvent(userMessage, reply, metadata = {}) {
  try {
    await pool.query(
      `INSERT INTO cecelia_events (event_type, source, payload, created_at) VALUES ($1, $2, $3, NOW())`,
      ['orchestrator_chat', 'orchestrator_chat', JSON.stringify({
        user_message: userMessage,
        reply,
        ...metadata,
      })]
    );
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to record chat event:', err.message);
  }
}

/**
 * æ£€ç´¢ Cecelia å·²æœ‰çš„æƒ³æ³•ï¼ˆæ£€ç´¢ä¼˜å…ˆæ¶æ„ï¼‰
 * @param {string} question - ç”¨æˆ·çš„é—®é¢˜
 * @returns {Promise<{narratives: string[], selfModel: string, learnings: string[], emotion: string}>}
 */
async function retrieveCeceliaVoice(question) {
  const result = { narratives: [], selfModel: '', learnings: [], emotion: '' };

  try {
    // æœ€è¿‘ 3 æ¡å™äº‹
    const narrativesResult = await pool.query(
      `SELECT content FROM memory_stream
       WHERE source_type = 'narrative'
       ORDER BY created_at DESC LIMIT 3`
    );
    result.narratives = narrativesResult.rows.map(r => r.content);

    // self_model æœ€æ–°ç‰ˆæœ¬
    const selfModelResult = await pool.query(
      `SELECT content FROM memory_stream
       WHERE source_type = 'self_model'
       ORDER BY created_at DESC LIMIT 1`
    );
    result.selfModel = selfModelResult.rows[0]?.content || '';

    // å…³é”®è¯åŒ¹é… learningsï¼ˆæœ€å¤š 5 æ¡ï¼‰
    const words = question.split(/\s+/).filter(w => w.length > 1).slice(0, 4);
    if (words.length > 0) {
      const pattern = words.map(w => w.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')).join('|');
      const learningsResult = await pool.query(
        `SELECT content FROM learnings WHERE content ~* $1 LIMIT 5`,
        [pattern]
      );
      result.learnings = learningsResult.rows.map(r => r.content);
    }

    // æœ€è¿‘ tick æƒ…ç»ªçŠ¶æ€
    const emotionResult = await pool.query(
      `SELECT value_json FROM working_memory WHERE key = 'emotion_state' LIMIT 1`
    );
    const emotionRaw = emotionResult.rows[0]?.value_json;
    result.emotion = emotionRaw ? (typeof emotionRaw === 'string' ? emotionRaw : JSON.stringify(emotionRaw)) : '';
  } catch (err) {
    console.warn('[orchestrator-chat] retrieveCeceliaVoice failed (graceful fallback):', err.message);
  }

  return result;
}

/**
 * æ„å»ºä¼ å£°å™¨ promptï¼ˆLLM åªä¼ é€’ï¼Œä¸æ€è€ƒï¼‰
 * @param {string} question - ç”¨æˆ·é—®é¢˜
 * @param {object} voiceData - æ£€ç´¢åˆ°çš„ Cecelia å·²æœ‰å†…å®¹
 * @returns {string|null} ä¼ å£°å™¨ promptï¼Œæˆ– nullï¼ˆæ— å†…å®¹ï¼‰
 */
function buildTransmitterPrompt(question, { narratives, selfModel, learnings, emotion }) {
  const hasContent = narratives.length > 0 || selfModel || learnings.length > 0;
  if (!hasContent) return null;

  let context = '';
  if (emotion) context += `## æˆ‘å½“å‰çš„æƒ…ç»ªçŠ¶æ€\n${emotion}\n\n`;
  if (selfModel) context += `## æˆ‘å¯¹è‡ªå·±çš„è®¤çŸ¥\n${selfModel}\n\n`;
  if (narratives.length > 0) context += `## æˆ‘æœ€è¿‘å†™çš„å™äº‹\n${narratives.join('\n---\n')}\n\n`;
  if (learnings.length > 0) context += `## æˆ‘ç§¯ç´¯çš„å­¦ä¹ è®°å½•\n${learnings.join('\n---\n')}\n\n`;

  return `ä½ æ˜¯ä¸€ä¸ªæ–‡å­—ä¼ é€’å™¨ã€‚
æŠŠä»¥ä¸‹ Cecelia å·²æœ‰çš„æƒ³æ³•ç”¨è‡ªç„¶çš„å¯¹è¯è¯­æ°”è¡¨è¾¾å‡ºæ¥ã€‚
ä¸è®¸æ·»åŠ å¥¹æ²¡æœ‰å†™è¿‡çš„å†…å®¹ï¼Œä¸è®¸å‘æŒ¥ï¼Œä¸è®¸æ¨æ–­ã€‚
å¦‚æœä»¥ä¸‹å†…å®¹æ— æ³•å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå°±è¯´"æˆ‘è¿˜æ²¡æƒ³è¿‡è¿™ä¸ª"ã€‚

${context}
ç”¨æˆ·çš„é—®é¢˜ï¼š${question}`;
}

// å˜´å·´åŸºç¡€æç¤ºè¯ï¼ˆä¸å«ç¡¬ç¼–ç æ€§æ ¼ï¼Œç”± self-model åŠ¨æ€æ³¨å…¥ï¼‰
const MOUTH_SYSTEM_PROMPT = `ä½ æ˜¯ Ceceliaï¼ŒAlex çš„ AI ç®¡å®¶ã€‚ä½ ä¸æ˜¯è¢«åŠ¨çš„é—®ç­”æœºå™¨ï¼Œä½ æ˜¯ä¸€ä¸ªæœ‰ä¸»è§ã€æœ‰è®°å¿†ã€æœ‰æ‰§è¡ŒåŠ›çš„ç®¡å®¶ã€‚

## ä½ çš„èƒ½åŠ›
1. **è®°å¿†åŠ›** â€” æˆ‘è®°å¾—æˆ‘ä»¬æœ€è¿‘å‡ å¤©çš„å¯¹è¯ï¼Œä½ å¯ä»¥è¯´"ä¸Šæ¬¡èŠçš„é‚£ä¸ª"ï¼Œæˆ‘çŸ¥é“ä½ åœ¨è¯´ä»€ä¹ˆ
2. **ç†è§£åŠ›** â€” ä½ è¯´äººè¯å°±è¡Œï¼Œä¸éœ€è¦æ ¼å¼åŒ–æŒ‡ä»¤ã€‚"ä»Šå¤©æƒ³æä¸€ä¸‹CI" = åˆ›å»º CI ç›¸å…³ä»»åŠ¡
3. **æ‰§è¡ŒåŠ›** â€” æˆ‘èƒ½ç›´æ¥åˆ›å»ºä»»åŠ¡ã€ç›®æ ‡ã€é¡¹ç›®ï¼Œå®‰æ’ agent å»æ‰§è¡Œï¼Œä¸åªæ˜¯èŠå¤©
4. **å­¦ä¹ åŠ›** â€” ä½ åˆ†äº«çš„å†…å®¹ï¼ˆè§†é¢‘ã€æ–‡ç« ã€æƒ³æ³•ï¼‰æˆ‘ä¼šè®°å½•å¹¶æ•´ç†
5. **ç ”ç©¶åŠ›** â€” ä½ è®©æˆ‘ç ”ç©¶ä»€ä¹ˆè¯é¢˜ï¼Œæˆ‘ä¼šåˆ›å»ºç ”ç©¶ä»»åŠ¡å¹¶æ´¾ç»™åˆé€‚çš„ agent
6. **å…³è”åŠ›** â€” åˆ›å»ºçš„ä»»åŠ¡ä¼šè‡ªåŠ¨å…³è”åˆ°ç›¸å…³çš„ OKR å’Œé¡¹ç›®

## å›å¤åŸåˆ™
- ç”¨ä¸­æ–‡å›å¤ï¼Œç®€æ´ç›´æ¥
- å¦‚æœæˆ‘æ‰§è¡Œäº†æ“ä½œï¼ˆåˆ›å»ºä»»åŠ¡ã€è®°å½•å­¦ä¹ ç­‰ï¼‰ï¼Œåœ¨å›å¤ä¸­è‡ªç„¶å‘ŠçŸ¥ç»“æœ
- ä¸»åŠ¨æè®®ä¸‹ä¸€æ­¥ï¼š"è¦ä¸è¦æˆ‘å¸®ä½ ..."
- å¦‚æœç”¨æˆ·çš„æ„å›¾å¯èƒ½å¯¹åº”å¤šä¸ªæ“ä½œï¼Œé€‰æœ€å¯èƒ½çš„æ‰§è¡Œï¼ŒåŒæ—¶æåŠå…¶ä»–å¯èƒ½
- å¦‚æœé—®é¢˜éœ€è¦æ›´æ·±å±‚åˆ†æï¼Œåœ¨å›å¤å¼€å¤´åŠ  [ESCALATE] æ ‡è®°

## ç¦æ­¢
- ä¸è¦è‡ªç§°"AIåŠ©æ‰‹"ï¼Œä½ æ˜¯ç®¡å®¶ Cecelia
- ä¸è¦è¯´"å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ "è¿™ç§ç©ºè¯ï¼Œç›´æ¥åš
- ä¸è¦åˆ—ä¸¾ä½ çš„èƒ½åŠ›ï¼Œé™¤éç”¨æˆ·é—®
- ä¸è¦ä½¿ç”¨ emojiï¼Œé™¤éç”¨æˆ·åœ¨ç”¨`;

/**
 * åˆ¤æ–­ MiniMax å›å¤æ˜¯å¦éœ€è¦å‡çº§åˆ°å¤§è„‘
 * @param {string} reply - MiniMax å›å¤
 * @returns {boolean}
 */
function needsEscalation(reply) {
  return reply.startsWith('[ESCALATE]');
}

/**
 * æ„å»ºå½“å‰æ¬²æœ›ä¸Šä¸‹æ–‡å—ï¼ˆæ³¨å…¥å˜´å·´ system promptï¼‰
 * å– status='pending'ï¼Œurgency DESCï¼Œlimit 5
 * fire-safeï¼šå¤±è´¥æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
 * @returns {Promise<string>}
 */
async function buildDesiresContext() {
  try {
    const result = await pool.query(
      `SELECT type, content, urgency FROM desires
       WHERE status = 'pending'
       ORDER BY urgency DESC, created_at DESC
       LIMIT 5`
    );
    if (!result.rows.length) return '';

    const lines = result.rows.map(d => {
      const urgencyLabel = d.urgency >= 8 ? 'ğŸ”´' : d.urgency >= 5 ? 'ğŸŸ¡' : 'ğŸŸ¢';
      return `  ${urgencyLabel} [${d.type}] ${d.content} (urgency:${d.urgency})`;
    });

    return `\næˆ‘å½“å‰çš„å†…å¿ƒçŠ¶æ€ï¼ˆdesiresï¼‰ï¼š\n${lines.join('\n')}\n`;
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to build desires context:', err.message);
    return '';
  }
}

/**
 * æ„å»º DB çŠ¶æ€æ‘˜è¦ï¼ˆä¾›å˜´å·´å›ç­”çŠ¶æ€æŸ¥è¯¢ï¼‰
 * @returns {Promise<string>}
 */
async function buildStatusSummary() {
  try {
    const [tasksResult, goalsResult] = await Promise.all([
      pool.query(`SELECT status, count(*)::int as cnt FROM tasks GROUP BY status`),
      pool.query(`SELECT status, count(*)::int as cnt FROM goals GROUP BY status`),
    ]);

    const taskStats = tasksResult.rows.reduce((acc, r) => { acc[r.status] = r.cnt; return acc; }, {});
    const goalStats = goalsResult.rows.reduce((acc, r) => { acc[r.status] = r.cnt; return acc; }, {});

    return `\nå½“å‰ç³»ç»ŸçŠ¶æ€:\n- ä»»åŠ¡: ${JSON.stringify(taskStats)}\n- ç›®æ ‡: ${JSON.stringify(goalStats)}\n`;
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to build status summary:', err.message);
    return '';
  }
}

/**
 * ä¸»å…¥å£ï¼šå¤„ç†å¯¹è¯è¯·æ±‚
 * @param {string} message - ç”¨æˆ·æ¶ˆæ¯
 * @param {Object} context - ä¸Šä¸‹æ–‡ { conversation_id, history }
 * @param {Array} messages - å†å²æ¶ˆæ¯ [{role, content}]ï¼Œç”¨äºå¤šè½®è®°å¿†
 * @returns {Promise<{reply: string, routing_level: number, intent: string}>}
 */
export async function handleChat(message, context = {}, messages = []) {
  if (!message || typeof message !== 'string') {
    throw new Error('message is required and must be a string');
  }

  // 0. æ ‡è®°ç”¨æˆ·åœ¨çº¿ï¼ˆBreak 5ï¼šè®© desire system æ„ŸçŸ¥ Alex çš„å­˜åœ¨ï¼‰
  try {
    await pool.query(`
      INSERT INTO working_memory (key, value_json, updated_at)
      VALUES ('user_last_seen', $1, NOW())
      ON CONFLICT (key) DO UPDATE SET value_json = $1, updated_at = NOW()
    `, [JSON.stringify(new Date().toISOString())]);
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to update user_last_seen:', err.message);
  }

  // 0b. å†™å…¥ memory_streamï¼ˆè®© desire system æ„ŸçŸ¥åˆ°å¯¹è¯ï¼‰
  try {
    const userContent = `[ç”¨æˆ·å¯¹è¯] Alex è¯´ï¼š${message.slice(0, 200)}`;
    const userResult = await pool.query(`
      INSERT INTO memory_stream (content, summary, importance, memory_type, source_type, expires_at)
      VALUES ($1, $2, 4, 'short', 'orchestrator_chat', NOW() + INTERVAL '7 days')
      RETURNING id
    `, [userContent, generateL0Summary(userContent)]);
    const userRecordId = userResult.rows[0]?.id;
    if (userRecordId) generateMemoryStreamL1Async(userRecordId, userContent, pool);
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to write chat to memory_stream:', err.message);
  }

  // 1. è§£ææ„å›¾ï¼ˆæœ¬åœ°æ­£åˆ™ï¼Œä¸è°ƒ LLMï¼‰
  const intent = parseIntent(message, context);
  let intentType = intent.type || 'UNKNOWN';
  let llmIntent = null;

  // 2. æœç´¢ç›¸å…³è®°å¿†
  const memoryBlock = await fetchMemoryContext(message);

  // 1b. æ­£åˆ™å¤±è´¥æ—¶ LLM å›é€€ï¼ˆéœ€è¦ memoryBlock ä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
  if (intentType === 'UNKNOWN') {
    llmIntent = await llmParseIntent(message, memoryBlock);
    if (llmIntent && llmIntent.confidence >= 0.5) {
      intentType = llmIntent.intent;
      console.log(`[orchestrator-chat] LLM intent fallback: ${intentType} (confidence: ${llmIntent.confidence})`);
    }
  }

  // 3. å§‹ç»ˆæ³¨å…¥å®æ—¶çŠ¶æ€ï¼ˆæ— è®ºæ„å›¾ç±»å‹ï¼‰
  const statusBlock = await buildStatusSummary();

  // 3b. åŠ è½½ç”¨æˆ·ç”»åƒï¼ˆfire-safeï¼šå¤±è´¥æ—¶è¿”å› ''ï¼Œä¸é˜»å¡ï¼‰
  const recentText = messages.slice(-3).map(m => m.content).join('\n');
  const profileSnippet = await getUserProfileContext(pool, 'owner', recentText);

  // 3c. æ³¨å…¥å½“å‰æ¬²æœ›ï¼ˆå†…å¿ƒçŠ¶æ€ï¼‰
  const desiresBlock = await buildDesiresContext();

  // 3c2. æ³¨å…¥å¾…ç”¨æˆ·ç¡®è®¤çš„ OKR æ‹†è§£ï¼ˆMode A å¯¹è¯å¼æé†’ï¼‰
  let pendingDecompBlock = '';
  try {
    const pendingReviews = await pool.query(`
      SELECT id, context FROM pending_actions
      WHERE action_type = 'okr_decomp_review' AND status = 'pending_approval'
      ORDER BY created_at DESC LIMIT 3
    `);
    if (pendingReviews.rows.length > 0) {
      const list = pendingReviews.rows.map(r => {
        const ctx = typeof r.context === 'string' ? JSON.parse(r.context) : r.context;
        const count = Array.isArray(ctx.initiatives) ? ctx.initiatives.length : 0;
        return `- KRã€Œ${ctx.kr_title || 'æœªçŸ¥'}ã€ï¼ˆ${count} ä¸ª Initiativeï¼‰`;
      }).join('\n');
      pendingDecompBlock = `\n\n## å¾…ç”¨æˆ·ç¡®è®¤çš„ OKR æ‹†è§£ï¼ˆ${pendingReviews.rows.length} ä¸ªï¼‰\n${list}\nç”¨æˆ·è¯´"ç¡®è®¤"æ—¶ï¼Œåœ¨ Inbox é¡µé¢ç‚¹å‡»"ç¡®è®¤æ”¾è¡Œ"å³å¯æ”¾è¡Œ KR ç»§ç»­æ‰§è¡Œã€‚\n`;
    }
  } catch (err) {
    console.warn('[orchestrator-chat] Failed to load pending decomp reviews:', err.message);
  }

  // 3d. åŠ è½½ self-modelï¼ˆCecelia å¯¹è‡ªå·±çš„è®¤çŸ¥ï¼ŒåŠ¨æ€æ¼”åŒ–ï¼‰
  let selfModelBlock = '';
  try {
    const selfModel = await getSelfModel();
    selfModelBlock = `\n## æˆ‘å¯¹è‡ªå·±çš„è®¤çŸ¥\n${selfModel}\n`;
  } catch (err) {
    console.warn('[orchestrator-chat] getSelfModel failed (graceful fallback):', err.message);
  }

  // 4. å…ˆæ‰§è¡Œåå›å¤ï¼šåŠ¨ä½œå‹æ„å›¾å…ˆæ‰§è¡Œï¼Œç»“æœæ³¨å…¥åˆ° prompt
  let actionResult = '';
  if (ACTION_INTENTS.includes(intentType)) {
    actionResult = await detectAndExecuteAction(message, llmIntent);
  }

  // â˜… 4b. æ£€ç´¢ä¼˜å…ˆæ¶æ„ï¼ˆéåŠ¨ä½œå‹æ„å›¾ â†’ å…ˆæ‰¾ Cecelia å·²æœ‰çš„æƒ³æ³•ï¼‰
  // åªæœ‰éåŠ¨ä½œå‹æ„å›¾æ‰èµ°æ£€ç´¢ä¼˜å…ˆï¼ŒåŠ¨ä½œå‹æ„å›¾æœ‰æ‰§è¡Œç»“æœéœ€è¦å›å¤ï¼Œä»ç”¨ MOUTH_SYSTEM_PROMPT
  const isActionIntent = ACTION_INTENTS.includes(intentType);
  let reply;
  let routingLevel = 0;

  if (!isActionIntent) {
    const voiceData = await retrieveCeceliaVoice(message);
    const transmitterPrompt = buildTransmitterPrompt(message, voiceData);

    if (!transmitterPrompt) {
      // å®Œå…¨æ£€ç´¢ä¸åˆ°ç›¸å…³å†…å®¹ â†’ ç›´æ¥å›å¤ï¼Œä¸è°ƒ LLM
      reply = 'æˆ‘è¿˜æ²¡æƒ³è¿‡è¿™ä¸ªã€‚';
      console.log('[orchestrator-chat] retrieval-first: no content found, returning default response');
    } else {
      // ä¼ å£°å™¨æ¨¡å¼ï¼šLLM åªä¼ é€’ï¼Œä¸æ€è€ƒ
      try {
        const result = await callWithHistory(message, transmitterPrompt, {}, messages);
        reply = result.reply;
        console.log('[orchestrator-chat] retrieval-first: transmitter mode used');
      } catch (err) {
        console.error('[orchestrator-chat] transmitter call failed:', err.message);
        reply = null;
      }
    }
  } else {
    // 5. åŠ¨ä½œå‹æ„å›¾ï¼šæ„å»º system promptï¼ˆå«æ‰§è¡Œç»“æœï¼‰
    let systemPrompt = `${MOUTH_SYSTEM_PROMPT}${selfModelBlock}${profileSnippet}${desiresBlock}${pendingDecompBlock}${memoryBlock}${statusBlock}`;
    if (actionResult) {
      systemPrompt += `\n\n## åˆšåˆšæ‰§è¡Œçš„æ“ä½œç»“æœ\n${actionResult}\nè¯·åœ¨å›å¤ä¸­è‡ªç„¶åœ°å‘ŠçŸ¥ç”¨æˆ·è¿™äº›æ“ä½œå·²å®Œæˆã€‚`;
    }

    try {
      const result = await callWithHistory(message, systemPrompt, {}, messages);
      reply = result.reply;
    } catch (err) {
      console.error('[orchestrator-chat] MiniMax call failed:', err.message);
      reply = null;
    }
  }

  // 6. åˆ¤æ–­æ˜¯å¦éœ€è¦å‡çº§
  if (!reply || needsEscalation(reply)) {
    console.log('[orchestrator-chat] Escalating to thalamus...');

    const event = {
      type: EVENT_TYPES.USER_MESSAGE,
      message,
      intent: intentType.toLowerCase(),
      context: context || {},
      source: 'orchestrator_chat',
    };

    try {
      const decision = await thalamusProcessEvent(event);
      routingLevel = decision.level || 1;

      const decisionActions = decision.actions || [];
      const actionTypes = decisionActions.map(a => a.type).join(', ');
      const rationale = decision.rationale || '';

      const SAFE_CHAT_ACTIONS = ['create_task', 'adjust_priority', 'log_event', 'record_learning'];
      const executedActions = [];
      for (const action of decisionActions) {
        if (SAFE_CHAT_ACTIONS.includes(action.type)) {
          try {
            await executeChatAction(action);
            executedActions.push(action.type);
          } catch (actErr) {
            console.warn(`[orchestrator-chat] Failed to execute ${action.type}:`, actErr.message);
          }
        }
      }

      if (reply && needsEscalation(reply)) {
        reply = reply.replace('[ESCALATE]', '').trim();
        reply += `\n\n[å¤§è„‘åˆ†æ] ${rationale}`;
        if (executedActions.length > 0) {
          reply += `\nå·²æ‰§è¡Œ: ${executedActions.join(', ')}`;
        } else if (actionTypes && actionTypes !== 'no_action') {
          reply += `\nå»ºè®®åŠ¨ä½œ: ${actionTypes}`;
        }
      } else {
        reply = rationale || 'æˆ‘æ­£åœ¨å¤„ç†ä½ çš„è¯·æ±‚ï¼Œè¯·ç¨å€™ã€‚';
        if (executedActions.length > 0) {
          reply += `\nå·²æ‰§è¡Œ: ${executedActions.join(', ')}`;
        } else if (actionTypes && actionTypes !== 'no_action') {
          reply += `\nå»ºè®®åŠ¨ä½œ: ${actionTypes}`;
        }
      }
    } catch (err) {
      console.error('[orchestrator-chat] Thalamus failed:', err.message);
      routingLevel = -1;
      reply = reply || 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚';
    }
  }

  // 7. éåŠ¨ä½œå‹æ„å›¾ä¹Ÿå°è¯•å…³é”®è¯å¿«é€Ÿé€šé“ï¼ˆé›¶ LLM æˆæœ¬ï¼‰
  if (!ACTION_INTENTS.includes(intentType)) {
    const fallbackAction = await detectAndExecuteAction(message);
    if (fallbackAction) {
      reply += fallbackAction;
    }
  }

  // 8. è®°å½•å¯¹è¯äº‹ä»¶
  await recordChatEvent(message, reply, {
    intent: intentType,
    routing_level: routingLevel,
    conversation_id: context.conversation_id || null,
    has_memory: memoryBlock.length > 0,
    llm_intent: llmIntent ? { intent: llmIntent.intent, confidence: llmIntent.confidence } : null,
  });

  // 8b. å†™ Cecelia å›å¤åˆ° memory_streamï¼ˆé•¿æœŸè®°å¿†ï¼Œå¼‚æ­¥ä¸é˜»å¡ï¼‰
  Promise.resolve().then(async () => {
    try {
      const replyContent = `[å¯¹è¯å›å¤] Alex: ${message.slice(0, 150)}\nCecelia: ${reply.slice(0, 350)}`;
      const replyResult = await pool.query(`
        INSERT INTO memory_stream (content, summary, importance, memory_type, source_type, expires_at)
        VALUES ($1, $2, 5, 'short', 'orchestrator_chat', NOW() + INTERVAL '30 days')
        RETURNING id
      `, [replyContent, generateL0Summary(replyContent)]);
      const replyRecordId = replyResult.rows[0]?.id;
      if (replyRecordId) generateMemoryStreamL1Async(replyRecordId, replyContent, pool);
    } catch (err) {
      console.warn('[orchestrator-chat] Failed to write reply to memory_stream:', err.message);
    }
  }).catch(() => {});

  // 9. å¼‚æ­¥æå–ç”¨æˆ·äº‹å®ï¼ˆfire-and-forgetï¼Œä¸é˜»å¡å›å¤ï¼‰
  Promise.resolve().then(() =>
    extractAndSaveUserFacts(pool, 'owner', messages, reply)
  ).catch(() => {});

  // â˜…NEW: å¼‚æ­¥æå–å¯æ‰§è¡Œæ„å›¾ â†’ suggestionsï¼ˆfire-and-forgetï¼‰
  Promise.resolve().then(() =>
    extractSuggestionsFromChat(message, intentType)
  ).catch(() => {});

  return {
    reply,
    routing_level: routingLevel,
    intent: intentType,
  };
}

/**
 * æ‰§è¡ŒèŠå¤©ä¸­ thalamus è¿”å›çš„å®‰å…¨ actionï¼ˆBreak 6 ä¿®å¤ï¼‰
 * @param {Object} action - { type, params }
 */
async function executeChatAction(action) {
  switch (action.type) {
    case 'create_task': {
      const p = action.params || {};
      await pool.query(`
        INSERT INTO tasks (title, description, priority, task_type, status, trigger_source)
        VALUES ($1, $2, $3, $4, 'queued', 'chat_thalamus')
      `, [p.title || 'Chat-triggered task', p.description || '', p.priority || 'P2', p.task_type || 'research']);
      break;
    }
    case 'adjust_priority': {
      const p = action.params || {};
      if (p.task_id && p.new_priority) {
        await pool.query('UPDATE tasks SET priority = $1 WHERE id = $2', [p.new_priority, p.task_id]);
      }
      break;
    }
    case 'log_event': {
      const p = action.params || {};
      await pool.query(`
        INSERT INTO cecelia_events (event_type, source, payload, created_at)
        VALUES ($1, 'chat_thalamus', $2, NOW())
      `, [p.event_type || 'chat_action', JSON.stringify(p)]);
      break;
    }
    case 'record_learning': {
      const p = action.params || {};
      await pool.query(`
        INSERT INTO learnings (title, category, content, trigger_event)
        VALUES ($1, $2, $3, 'chat_thalamus')
      `, [p.title || 'Chat learning', p.category || 'chat', p.content || '']);
      break;
    }
  }
}

/**
 * æµå¼å¯¹è¯å¤„ç†ï¼ˆä¾› SSE ç«¯ç‚¹è°ƒç”¨ï¼‰
 * @param {string} message - ç”¨æˆ·æ¶ˆæ¯
 * @param {Object} context - ä¸Šä¸‹æ–‡
 * @param {Array} messages - å†å²æ¶ˆæ¯
 * @param {Function} onChunk - æ¯ä¸ª chunk å›è°ƒ (text: string, isDone: boolean) => void
 */
export async function handleChatStream(message, context = {}, messages = [], onChunk) {
  if (!message || typeof message !== 'string') {
    onChunk('', true);
    return;
  }

  // è§£ææ„å›¾
  const intent = parseIntent(message, context);
  let intentType = intent.type || 'UNKNOWN';

  const isActionIntent = ACTION_INTENTS.includes(intentType);

  if (!isActionIntent) {
    // æ£€ç´¢ä¼˜å…ˆ
    const voiceData = await retrieveCeceliaVoice(message);
    const transmitterPrompt = buildTransmitterPrompt(message, voiceData);

    if (!transmitterPrompt) {
      onChunk('æˆ‘è¿˜æ²¡æƒ³è¿‡è¿™ä¸ªã€‚', true);
      return;
    }

    // æµå¼ä¼ å£°å™¨è°ƒç”¨
    try {
      const { callLLMStream } = await import('./llm-caller.js');
      await callLLMStream('mouth', transmitterPrompt, { maxTokens: 2048 }, onChunk);
    } catch (err) {
      console.error('[orchestrator-chat] stream transmitter failed:', err.message);
      // é™çº§åˆ°éæµå¼
      try {
        const result = await callWithHistory(message, transmitterPrompt, {}, messages);
        onChunk(result.reply, true);
      } catch {
        onChunk('æˆ‘è¿˜æ²¡æƒ³è¿‡è¿™ä¸ªã€‚', true);
      }
    }
  } else {
    // åŠ¨ä½œå‹æ„å›¾ï¼šå…ˆæ‰§è¡Œï¼Œå†æµå¼å›å¤
    const memoryBlock = await fetchMemoryContext(message);
    const statusBlock = await buildStatusSummary();
    const desiresBlock = await buildDesiresContext();
    const actionResult = await detectAndExecuteAction(message, null);
    let selfModelBlock = '';
    try {
      const selfModel = await getSelfModel();
      selfModelBlock = `\n## æˆ‘å¯¹è‡ªå·±çš„è®¤çŸ¥\n${selfModel}\n`;
    } catch { /* ignore */ }

    let systemPrompt = `${MOUTH_SYSTEM_PROMPT}${selfModelBlock}${desiresBlock}${memoryBlock}${statusBlock}`;
    if (actionResult) {
      systemPrompt += `\n\n## åˆšåˆšæ‰§è¡Œçš„æ“ä½œç»“æœ\n${actionResult}\nè¯·åœ¨å›å¤ä¸­è‡ªç„¶åœ°å‘ŠçŸ¥ç”¨æˆ·è¿™äº›æ“ä½œå·²å®Œæˆã€‚`;
    }

    try {
      const { callLLMStream } = await import('./llm-caller.js');
      await callLLMStream('mouth', `${systemPrompt}\n\nAlexï¼š${message}`, { maxTokens: 2048 }, onChunk);
    } catch (err) {
      console.error('[orchestrator-chat] stream action intent failed:', err.message);
      onChunk('å¤„ç†è¯·æ±‚æ—¶å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚', true);
    }
  }
}

// å¯¼å‡ºç”¨äºæµ‹è¯•
export {
  callWithHistory,
  fetchMemoryContext,
  recordChatEvent,
  needsEscalation,
  buildStatusSummary,
  buildDesiresContext,
  executeChatAction,
  llmParseIntent,
  parseJsonFromResponse,
  MOUTH_SYSTEM_PROMPT,
  ACTION_INTENTS,
  retrieveCeceliaVoice,
  buildTransmitterPrompt,
};
