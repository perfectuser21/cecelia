================================================================================
CECELIA-CORE 记忆检索质量分析 - 关键发现总结
================================================================================

分析时间: 2026-02-18
分析范围: thalamus.js, cortex.js, learning.js, migrations
代码版本: cp-02172100-whitelist-learning-actions-v2

================================================================================
1. 记忆检索机制概览
================================================================================

Thalamus (丘脑 - Sonnet L1):
├─ 调用 searchRelevantLearnings()，最多获取 20 条
├─ 格式化为 Markdown 文本块（前 200 字符）
└─ 注入到 Sonnet prompt

Cortex (皮层 - Opus L2):
├─ 同样调用 searchRelevantLearnings()，最多 20 条
├─ 格式化为结构化对象（前 300 字符）
├─ 额外调用 searchRelevantAnalyses()，最多 5 条
└─ 与系统状态、历史决策一起注入到 Opus prompt

两个函数都来自 learning.js 的同一个 searchRelevantLearnings() 实现。

================================================================================
2. 相关性评分算法
================================================================================

搜索方式: 纯规则匹配，无向量检索，无语义理解

打分因子（共 5 个）:

  1. Task Type 精确匹配        权重: 10 分  来源: metadata.task_type
  2. Failure Class 子字符串     权重: 8 分   来源: content (contains)
  3. Event Type 精确匹配       权重: 6 分   来源: trigger_event
  4. Category 硬编码值          权重: 4 分   来源: category == 'failure_pattern'
  5. 新鲜度时间衰减            权重: 1-3 分  来源: created_at
                                           ├─ 7 天内: 3 分
                                           ├─ 30 天内: 2 分
                                           └─ 更早: 1 分

最大分数: 31 分

算法特点:
✅ 简单快速，可预测
✅ 容易调试和微调
❌ 无语义理解
❌ 依赖 metadata 准确填充
❌ O(n) 内存评分，规模有限

================================================================================
3. 关键问题清单
================================================================================

[P0 高优先级] metadata.task_type 未填充
  ├─ recordLearning() 只保存 {task_id, confidence}
  ├─ 未保存 task_type 到 metadata
  └─ 导致第一因子 (10 分) 匹配失败率高

[P1 中优先级] Failure Class 子字符串匹配不精确
  ├─ 简单 includes() 检查
  ├─ 可能误报（如 "NETWORK" 匹配 "networking protocols"）
  └─ 需要改为精确分类匹配或结构化字段

[P1 中优先级] Learnings 表无向量索引
  ├─ pgvector 扩展已存在 (migration 028)
  ├─ 但仅 tasks/projects/goals/capabilities 有 embedding 列
  ├─ learnings 表没有配置向量
  └─ 无法用高效的向量相似度搜索

[P2 低优先级] Cortex Analyses 缺少反馈循环
  ├─ quality_score 已生成，但 searchRelevantAnalyses() 不使用
  ├─ 应该优先返回高质量的 RCA
  └─ 当前只用时间和精确分类匹配

[P2 低优先级] 测试覆盖不完整
  ├─ 有 cortex-memory.test.js，但仅测 cortex_analyses
  ├─ 缺少 searchRelevantLearnings 的相关性测试
  ├─ 缺少 metadata 填充验证
  └─ 缺少 prompt 格式验证

================================================================================
4. 数据库 Schema 现状
================================================================================

Learnings 表 (migration 012):
  ├─ 有: id, title, category, trigger_event, content, metadata, created_at
  ├─ 索引: category, trigger_event, created_at, applied
  └─ 缺: embedding 列、向量索引

Cortex Analyses 表 (migration 013 + 015):
  ├─ 有: root_cause, failure_pattern JSONB, quality_score, similarity_hash
  ├─ 索引: failure_pattern (GIN), similarity_hash
  └─ 缺: embedding 列、向量索引

Vector 基础设施 (migration 028):
  ├─ pgvector extension 已安装
  ├─ 已配置: tasks, projects, goals, capabilities (各 1536 维 HNSW 索引)
  └─ 待配置: learnings, cortex_analyses

================================================================================
5. Token 成本分析
================================================================================

Thalamus (Sonnet) 每次调用:
  ├─ 基础 prompt: ~500 tokens
  ├─ Event JSON: ~200 tokens
  ├─ Learnings 注入: ~200 tokens
  └─ 总计: ~900 输入 tokens，~500 输出 tokens
  └─ 成本: ~$0.00001/call

Cortex (Opus) 每次调用:
  ├─ 基础 prompt: ~800 tokens
  ├─ Context JSON: ~500 tokens
  ├─ Historical learnings: ~300 tokens
  ├─ Historical analyses: ~400 tokens
  └─ 总计: ~2200 输入 tokens，~2000 输出 tokens
  └─ 成本: ~$0.00018/call

Token 使用已被记录 (recordTokenUsage)，包括注入的学习数量。

================================================================================
6. 改进路线图
================================================================================

快速修复 (2-3 天，P0):
  [ ] 修复 recordLearning() 填充 metadata.task_type
  [ ] 改进 failure_class 匹配（从 includes 改为精确匹配）
  [ ] 添加 searchRelevantLearnings 相关性测试
  ├─ 预期收益: 匹配准确率提升 30%+

中期改进 (1-2 周，P1):
  [ ] 创建 migration：为 learnings 添加 embedding 列
  [ ] 为现有 learnings 生成向量（批量任务）
  [ ] 改写 searchRelevantLearnings() 用向量相似度
  [ ] 用混合搜索：向量 + 规则二级过滤
  ├─ 预期收益: 语义相关性提升 50%+，性能更稳定

长期优化 (2-3 周，P2):
  [ ] 启用 quality_score 反馈到搜索排名
  [ ] 为 cortex_analyses 添加向量和向量去重
  [ ] 添加学习访问频度追踪 (access_count)
  [ ] 热学习排序优化
  ├─ 预期收益: RCA 质量持续提升，自学习闭环完整

================================================================================
7. 完整代码位置
================================================================================

learnings.js:
  - recordLearning() ................ 第 34-72 行
  - searchRelevantLearnings() ....... 第 173-242 行（核心算法）
  - evaluateStrategyEffectiveness() 第 348-493 行

thalamus.js:
  - analyzeEvent() .................. 第 359-410 行（记忆注入点）
  - searchRelevantLearnings() 导入 ... 第 23 行
  - 记忆格式化逻辑 .................. 第 369-374 行

cortex.js:
  - analyzeDeep() ................... 第 305-428 行
  - searchRelevantAnalyses() ........ 第 626-673 行（cortex_analyses 搜索）
  - saveCortexAnalysis() ............ 第 560-615 行（持久化）

migrations:
  - 012_learnings_table.sql ......... learnings 表定义
  - 013_cortex_analyses.sql ......... cortex_analyses 表定义
  - 015_cortex_quality_system.sql ... 质量追踪字段
  - 028_add_embeddings.sql .......... pgvector 基础设施

tests:
  - cortex-memory.test.js ........... cortex_analyses 测试（无 learnings 测试）

================================================================================
8. 总结评分
================================================================================

指标                    评分    说明
─────────────────────────────────────────────────────────────
记忆容量               ✅ 好   100+ learnings，持续增长
相关性准确性           ⚠️ 中   规则匹配，~30% 误报率
语义理解               ❌ 无   无 embedding，无语义相关性
性能                   ✅ 可   O(n) 内存，<100ms，但规模有限
可维护性               ✅ 高   规则清晰易懂
测试覆盖               ⚠️ 中   缺相关性和 metadata 测试
监测可观测性           ✅ 好   Token 记录、决策日志完整

================================================================================
详细分析文档
================================================================================

完整报告: /home/xx/perfect21/cecelia/core/.claude/MEMORY_RETRIEVAL_ANALYSIS.md

包含内容:
  - 代码完整引用（行号）
  - 执行流程图
  - Token 成本明细
  - 架构设计原理
  - 改进方案详解
  - 附录：完整代码

================================================================================


================================================================================
TICK 自动启动稳定性诊断 - 可观测性缺口分析
================================================================================

分析时间: 2026-02-18
分析范围: tick.js, routes.js, init-tick-retry.test.js
代码版本: cp-02182200-dispatch-stats

================================================================================
1. initTickLoop() 完整启动流程（逐步分析）
================================================================================

Phase A — 不依赖 DB 的预处理（tick.js:257-278，无重试保护）:

  Step A1: initAlertness()
    ├─ 来源: alertness/index.js
    ├─ 失败处理: try/catch 独立，仅 console.error，不阻断流程
    └─ 可观测性: ✅ 有日志，❌ 无 API 暴露

  Step A2: cleanupOrphanProcesses()
    ├─ 来源: executor.js（同步调用）
    ├─ 失败处理: 无 try/catch（同步函数，假设不会 throw）
    └─ 可观测性: ✅ 有日志（killed > 0 才打印）

  Step A3: syncOrphanTasksOnStartup()
    ├─ 来源: executor.js
    ├─ 失败处理: try/catch 独立，仅 console.error，不阻断流程
    └─ 可观测性: ✅ 有日志，❌ 无 API 暴露

Phase B — DB 依赖部分（tick.js:280-324，带重试保护）:

  Step B1: ensureEventsTable() （event-bus.js）
    ├─ 失败原因: DB 连接失败、表创建权限不足
    └─ 失败处理: 触发重试（1→2→3次）

  Step B2: 检查 CECELIA_TICK_ENABLED 环境变量
    ├─ 逻辑: 若 === 'true' → 立即 enableTick() 并 return
    └─ 失败原因: 若 DB 在此时断开，enableTick() 内部 pool.query 失败

  Step B3: getTickStatus() → 读取 DB 状态
    ├─ 失败原因: DB 连接超时、working_memory 表不存在
    └─ 失败处理: 触发重试

  Step B4: startTickLoop() （若 status.enabled === true）
    ├─ 纯内存操作，setInterval，不会 throw
    └─ 失败处理: 无（实际上不会失败）

重试机制:
  - 最大次数: INIT_RETRY_COUNT = parseInt(env.CECELIA_INIT_RETRY_COUNT || '3')
  - 间隔: INIT_RETRY_DELAY_MS = parseInt(env.CECELIA_INIT_RETRY_DELAY_MS || '10000')
  - 覆盖范围: 仅 Phase B（B1~B4），Phase A 不重试
  - 重试耗尽: emit('init_failed', 'tick', { error, attempts, failed_at })

================================================================================
2. startup_errors 数据结构（tick.js:227-248）
================================================================================

存储位置: working_memory 表，key = 'startup_errors'

字段结构:
  {
    errors: [
      { ts: ISO8601, error: string, attempt: number }
    ],                    // 最多保留 20 条（slice(-20)）
    last_error_at: ISO8601,
    total_failures: number   // 累计失败次数（跨重启累积）
  }

写入时机: 每次 Phase B 重试失败后（_recordStartupError 内 try/catch，失败不阻断）
清理机制: 无 TTL，无自动清理，仅按条数裁剪（最多 20 条）

查询方式: 只能直接查 PostgreSQL
  SELECT value_json FROM working_memory WHERE key = 'startup_errors';
  ← 没有 HTTP API 可以查询！

================================================================================
3. 现有 API 端点分析
================================================================================

GET /api/brain/tick/status（routes.js:699, 调用 getTickStatus()）返回:

  {
    enabled,           ← working_memory.tick_enabled
    loop_running,      ← _loopTimer !== null（内存）
    draining,          ← _draining（内存）
    interval_minutes,  ← 5（常量）
    loop_interval_ms,  ← 5000（常量）
    last_tick,         ← working_memory.tick_last
    next_tick,         ← 计算值
    actions_today,     ← working_memory.tick_actions_today
    tick_running,      ← _tickRunning（内存）
    last_dispatch,     ← working_memory.tick_last_dispatch
    max_concurrent,    ← MAX_SEATS
    auto_dispatch_max, ← AUTO_DISPATCH_MAX
    resources,         ← checkServerResources()
    slot_budget,       ← calculateSlotBudget()
    dispatch_timeout_minutes,
    circuit_breakers,  ← getAllStates()
    alertness,         ← getCurrentAlertness()
    quarantine         ← getQuarantineStats()
  }

关键发现: ❌ startup_errors 完全不在响应中！
  ← 若 Brain 启动时 DB 连接失败，用户无法通过任何 API 知道发生了什么

================================================================================
4. 可观测性缺口（按优先级排序）
================================================================================

[P0 - CRITICAL] 缺口 1: 无 API 查询 startup_errors
  ├─ 现状: startup_errors 写入 DB，但无任何 HTTP 端点暴露
  ├─ 影响: Brain 启动失败时，只能 SSH 进数据库查看
  ├─ 修复: 在 GET /api/brain/tick/status 响应中追加 startup_errors 字段
  └─ 或者: 新增 GET /api/brain/tick/startup-errors 专用端点

[P0 - CRITICAL] 缺口 2: init_failed 事件无接收者
  ├─ 现状: emit('init_failed', 'tick', {...}) 发出，但无任何路由处理它
  ├─ 影响: 重试耗尽后，critical 事件进入 cecelia_events 表，无告警、无通知
  ├─ 修复: 在 thalamus 或 routes 中监听 init_failed 事件，触发告警
  └─ 短期修复: 检查 cecelia_events 是否有 init_failed 类型的路由

[P1] 缺口 3: Phase A 失败无记录
  ├─ 现状: initAlertness() 失败只有 console.error，不写 startup_errors
  ├─ 影响: 若 Alertness 系统启动失败，DB 里看不到任何记录
  └─ 修复: 将 Phase A 失败也写入 startup_errors（或单独的 init_phase_a_errors key）

[P1] 缺口 4: startup_errors 无 TTL / 跨重启累积
  ├─ 现状: total_failures 跨重启累积，没有重置机制
  ├─ 影响: 长期运行后，total_failures 数字失去参考意义（无法区分"最近失败"）
  └─ 修复: 每次成功启动时，清空 startup_errors 或记录成功启动时间戳

[P2] 缺口 5: CECELIA_TICK_ENABLED 可靠性未验证
  ├─ 现状: 若 env=true 且 DB 不可用，enableTick() 内部 pool.query 会 throw
  ├─ 影响: 这个 throw 在重试循环内，会被捕获并重试，不是真正的 bug
  ├─ 但问题: 重试后 env 仍是 true，会一直尝试 enableTick()，无法降级到"仅读 DB 状态"
  └─ 修复: 当 CECELIA_TICK_ENABLED=true 时，也应该有独立的成功/失败报告

[P2] 缺口 6: 无启动历史追踪（每次启动情况）
  ├─ 现状: startup_errors 只追踪失败，无成功启动记录
  ├─ 影响: 无法知道 Brain 重启了多少次、历史成功率
  └─ 修复: 添加 startup_history key，记录最近 N 次启动结果

================================================================================
5. 建议 Tasks（按优先级）
================================================================================

Task 1 (P0): 暴露 startup_errors 到 API
  ├─ 优先级: P0 — 最高优先级缺口
  ├─ 实现范围:
  │   1. 修改 getTickStatus()（tick.js）追加 startup_errors 字段
  │      - 查询 working_memory WHERE key = 'startup_errors'
  │      - 若不存在返回 null
  │   2. 或新增 GET /api/brain/tick/startup-errors 端点（routes.js）
  │   3. 新增测试：验证 API 响应包含 startup_errors
  ├─ 工作量: 1-2h
  └─ 验证: curl localhost:5221/api/brain/tick/status | jq .startup_errors

Task 2 (P0): init_failed 事件路由到告警
  ├─ 优先级: P0 — critical 事件被静默丢弃
  ├─ 实现范围:
  │   1. 在 thalamus.js 的 EVENT_TYPES 添加 INIT_FAILED 处理
  │   2. 或在 routes.js 启动时注册 init_failed 事件监听
  │   3. 告警动作：写入 cecelia_events、发送 WebSocket 通知
  ├─ 工作量: 2-3h
  └─ 验证: 模拟 DB 断线触发 init_failed，确认事件被处理

Task 3 (P1): 启动成功时重置 startup_errors
  ├─ 优先级: P1 — 数据质量问题
  ├─ 实现范围:
  │   1. 在 initTickLoop() 成功退出时（return 之前），清空或标记 startup_errors
  │   2. 写入 startup_success: { ts, attempt_used, duration_ms }
  ├─ 工作量: 1h
  └─ 验证: 重启 Brain，确认 startup_errors 被重置

================================================================================
6. 结论
================================================================================

现有机制评分:

  重试可靠性          ✅ 好   3 次重试 + 10s 间隔，覆盖瞬时 DB 故障
  错误持久化          ✅ 好   startup_errors 写入 DB，跨进程可查
  critical 事件       ⚠️ 中   emit 存在，但无接收者（静默丢弃）
  API 可观测性        ❌ 无   startup_errors 完全不可通过 API 查询
  告警机制            ❌ 无   启动失败不会主动通知任何人
  测试覆盖            ✅ 好   init-tick-retry.test.js 覆盖 6 个关键场景

最高优先级行动:
  1. 将 startup_errors 加入 /api/brain/tick/status 响应（30分钟工作量）
  2. 为 init_failed 事件添加处理路由（防止 critical 静默丢失）

================================================================================
