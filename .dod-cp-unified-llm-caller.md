## DoD - 统一 LLM 调用层

### 验收清单

- [ ] **D1**: `llm-caller.js` 模块创建，导出 `callLLM(agentId, prompt, options)` 函数
  - Test: 单元测试 mock bridge，验证 Anthropic 路径走 /llm-call、MiniMax 路径走 MiniMax API

- [ ] **D2**: cecelia-bridge 新增 `/llm-call` 端点（轻量同步 LLM 调用）
  - Test: curl POST localhost:3457/llm-call 返回 claude 响应

- [ ] **D3**: `thalamus.js` 的 `callThalamLLM()` 和 `callHaiku()` 替换为 `callLLM('thalamus', prompt)`
  - Test: thalamus 测试通过

- [ ] **D4**: `cortex.js` 的 `callCortexLLM()` 替换为 `callLLM('cortex', prompt)`
  - Test: cortex 相关测试通过

- [ ] **D5**: `reflection.js` 的 `callOpusReflection()` 替换为 `callLLM('reflection', prompt)`
  - Test: desire-system 测试中 reflection 测试通过

- [ ] **D6**: `memory.js` 的 `scoreImportance()` 改为批量调用 `callLLM('mouth', batchPrompt)`
  - Test: 一次 LLM 调用打完所有观察的分

- [ ] **D7**: `desire-formation.js` 的 `generateDesireFromInsight()` 替换为 `callLLM('mouth', prompt)`
  - Test: desire-formation 测试通过

- [ ] **D8**: `expression.js` 的 `generateMessage()` 替换为 `callLLM('mouth', prompt)`
  - Test: expression 测试通过

- [ ] **D9**: `orchestrator-chat.js` 的 `callMiniMax()` 替换为 `callLLM('mouth', prompt)`
  - Test: orchestrator-chat 测试通过

- [ ] **D10**: `model-profile.js` FALLBACK_PROFILE 默认改为 Anthropic 模型
  - Test: FALLBACK_PROFILE.config.thalamus.provider === 'anthropic'

- [ ] **D11**: 所有现有测试通过 `npm test -w packages/brain`（desire-system + orchestrator-chat）
  - Test: npm test 通过
