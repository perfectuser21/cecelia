---
id: prd-memory-upgrade
version: 3.0.0
created: 2026-02-22
updated: 2026-02-22
changelog:
  - 3.0.0: Phase 3 — MMR 精排 + 可观测性
  - 2.1.0: Phase 2 — Learnings 向量化（v1.68.0, PR #434）
  - 2.0.0: 融合大模型记忆四层架构，重新排序 Phase（统一检索器优先）
  - 1.0.0: 初始版本
---

# PRD: Cecelia 记忆系统升级

## 背景

### 现状

Cecelia 的记忆系统当前由以下组件构成：

| 组件 | 文件 | 功能 | 问题 |
|------|------|------|------|
| similarity.js | 向量 + Jaccard 混合搜索 | 搜索 tasks/capabilities | 无时间衰减，无结果去重 |
| memory-service.js | API 封装（summary/detail/related） | 给 thalamus 用 | 功能完整，但数据源单一 |
| thalamus.js | buildMemoryBlock() + learningBlock | 决策时注入 top 3 任务 + 20 条 learnings | 两段独立注入，无 token 预算 |
| learning.js | searchRelevantLearnings() | 关键词匹配 learnings 表 | **不是向量搜索**，String.includes() 匹配 |
| embedding-service.js | fire-and-forget 生成 task 向量 | 新建任务时自动向量化 | 只向量化 tasks，不向量化 learnings |

### 核心问题

1. **Token 溢出**：thalamus 注入 20 条 learnings + 3 条 memory，无上限，context 被低质量信息淹没
2. **记忆不衰减**：3 个月前的任务和昨天的任务同权重
3. **Learnings 形同虚设**：关键词匹配，"认证失败"搜不到"auth error"
4. **搜索结果重复**：无去重，可能返回 3 条几乎相同的结果
5. **无可观测性**：不知道注入的记忆是否被 thalamus 实际使用

---

## 架构：三层记忆模型

基于大模型记忆四层架构（Working / Semantic / Episodic / Profile），映射到 Cecelia 现有基础设施：

| 记忆层 | Cecelia 数据源 | 检索方式 | 衰减策略 |
|--------|---------------|---------|---------|
| **语义记忆** (Semantic) | tasks + learnings + capabilities 的 embedding | 向量搜索 + Jaccard fallback | tasks: 半衰期 30 天, learnings: 90 天, capabilities: 不衰减 |
| **事件记忆** (Episodic) | cecelia_events | 时间窗口 + type 过滤 | 24h 窗口（debug 模式 72h） |
| **画像配置** (Profile) | goals (OKR) + capabilities + 系统配置 | 直接加载（不搜索） | 不衰减 |

**Working Memory 暂不实现**：thalamus 当前是无状态单次调用（event → decision），没有多步推理链（chain）。Working Memory 预留接口，等 thalamus 有 chain 能力时接入。

### 统一入口

```
buildMemoryContext({query, mode, tokenBudget})
│
├── 1. 并行检索（3 路）
│   ├── vectorSearch(tasks + learnings)  → 候选集 A（带 source 标签）
│   ├── loadRecentEvents(24h, type过滤)  → 候选集 B
│   └── loadActiveProfile()              → 固定片段（OKR + 能力摘要）
│
├── 2. 统一评分
│   score = relevance × timeDecay(halfLife[source]) × modeWeight[source][mode]
│
├── 3. MMR 去重（跨数据源）
│
├── 4. Token 预算截断
│   ├── Profile 片段优先（~100 tokens，always）
│   └── 按 score 从高到低填入，超预算截断
│
└── 5. 返回格式化 context block
```

### Mode Weight 配置

不同决策模式下，各数据源的权重不同：

| source | plan | execute | debug | chat |
|--------|------|---------|-------|------|
| task | 1.0 | 1.2 | 1.0 | 0.8 |
| learning | 0.8 | 1.0 | 1.5 | 0.6 |
| event | 0.5 | 0.8 | 1.5 | 0.3 |
| okr | 1.5 | 0.5 | 0.3 | 1.0 |

---

## 目标

**让 Cecelia 的记忆系统从"随缘注入"升级到"精准召回、预算可控、可观测"。**

### 量化目标

| 指标 | 现状 | 目标 |
|------|------|------|
| thalamus 记忆注入 token 数 | 无限制（可达 3000+） | ≤ 800 tokens（可配置） |
| 搜索结果多样性 | 可能 3 条重复 | top 5 结果两两 Jaccard < 0.8 |
| learnings 检索方式 | 关键词（String.includes） | 向量搜索 + 关键词 boost |
| 时间衰减 | 无 | 30 天半衰期（tasks），90 天（learnings） |
| 可观测性 | 无 | memory_hit_rate 指标存入 cecelia_events |

---

## 方案设计

### Phase 1: 统一记忆检索器 + Token 预算（止血）

**核心目标**：建立 `memory-retriever.js`，替换 thalamus 的双注入逻辑，立即控制 token 溢出。

**新建文件**：`brain/src/memory-retriever.js`

#### 1.1 buildMemoryContext() 主函数

```javascript
/**
 * 统一记忆检索入口
 * @param {Object} options
 * @param {string} options.query - 搜索查询文本
 * @param {string} options.mode - 'plan' | 'execute' | 'debug' | 'chat'
 * @param {number} options.tokenBudget - token 上限（默认 800）
 * @param {Object} options.pool - pg pool
 * @returns {string} 格式化的 context block
 */
export async function buildMemoryContext({ query, mode = 'execute', tokenBudget = 800, pool }) {
  // 1. 并行检索
  const [semanticResults, eventResults, profileSnippet] = await Promise.all([
    searchSemanticMemory(pool, query, mode),
    loadRecentEvents(pool, query, mode),
    loadActiveProfile(pool, mode),
  ]);

  // 2. 统一评分（语义 + 事件混合，profile 不参与评分）
  const candidates = [...semanticResults, ...eventResults];
  const scored = candidates.map(c => ({
    ...c,
    finalScore: c.relevance * timeDecay(c.created_at, HALF_LIFE[c.source]) * MODE_WEIGHT[c.source][mode],
  }));

  // 3. 简单去重（Jaccard > 0.8 的丢掉后面的）
  const deduped = simpleDedup(scored, 0.8);

  // 4. 按 finalScore 排序 + token 预算截断
  deduped.sort((a, b) => b.finalScore - a.finalScore);
  const block = formatWithBudget(deduped, profileSnippet, tokenBudget);

  return block;
}
```

#### 1.2 时间衰减

```javascript
const HALF_LIFE = {
  task: 30,        // 任务：30 天半衰期
  learning: 90,    // 经验：90 天
  event: 1,        // 事件：1 天（24h 窗口已过滤，衰减快速）
  okr: Infinity,   // OKR：不衰减
  capability: Infinity, // 能力：不衰减
};

function timeDecay(createdAt, halfLifeDays) {
  if (!halfLifeDays || halfLifeDays === Infinity) return 1;
  const ageDays = (Date.now() - new Date(createdAt).getTime()) / 86400000;
  return Math.exp(-ageDays * Math.LN2 / halfLifeDays);
}
```

#### 1.3 简单去重

Phase 1 不做完整 MMR（留到 Phase 3），只做简单的 Jaccard 阈值去重：

```javascript
function simpleDedup(scored, threshold = 0.8) {
  const result = [];
  for (const item of scored.sort((a, b) => b.finalScore - a.finalScore)) {
    const isDuplicate = result.some(r => jaccardSimilarity(r.text, item.text) > threshold);
    if (!isDuplicate) result.push(item);
  }
  return result;
}
```

#### 1.4 Token 预算格式化

```javascript
function formatWithBudget(items, profileSnippet, budget) {
  let block = '';
  let used = 0;

  // Profile 优先（~100 tokens）
  if (profileSnippet) {
    const profileTokens = estimateTokens(profileSnippet);
    block += profileSnippet + '\n';
    used += profileTokens;
  }

  // 按 score 从高到低填入
  block += '\n## 相关历史上下文\n';
  used += 10;

  for (const item of items) {
    const line = formatItem(item);
    const lineTokens = estimateTokens(line);
    if (used + lineTokens > budget) break;
    block += line + '\n';
    used += lineTokens;
  }

  return block;
}

// 简单 token 估算：中文约 1.5 字/token，英文约 4 字符/token
function estimateTokens(text) {
  return Math.ceil(text.length / 2.5);
}
```

#### 1.5 数据源适配器

```javascript
// 语义记忆：复用现有 similarity.js（需修改 vectorSearch 返回 created_at）
async function searchSemanticMemory(pool, query, mode) {
  const results = await searchWithVectors(pool, query, { topK: 20 });
  return results.map(r => ({
    ...r,
    source: r.type || 'task',  // task / capability
    text: `${r.title} ${r.description || ''}`,
    relevance: r.score,
  }));
  // Phase 1 不搜 learnings 向量（还没有 embedding），沿用现有关键词搜索
  // Phase 2 接入后自动加入
}

// 事件记忆：时间窗口 + type 过滤（不做向量搜索）
async function loadRecentEvents(pool, query, mode) {
  const hours = mode === 'debug' ? 72 : 24;
  const rows = await pool.query(`
    SELECT id, type, payload, created_at
    FROM cecelia_events
    WHERE created_at > NOW() - INTERVAL '${hours} hours'
      AND type IN ('task_failed', 'task_completed', 'alert', 'layer2_health', 'escalation')
    ORDER BY created_at DESC
    LIMIT 10
  `, []);
  return rows.rows.map(r => ({
    id: r.id,
    source: 'event',
    text: `[${r.type}] ${JSON.stringify(r.payload).substring(0, 200)}`,
    relevance: 0.5, // 事件基础分，靠 modeWeight 调节
    created_at: r.created_at,
  }));
}

// 画像配置：直接加载（不参与评分排序）
async function loadActiveProfile(pool, mode) {
  if (mode === 'chat') return ''; // 聊天模式不需要 OKR

  const goals = await pool.query(`
    SELECT title, status, progress FROM goals
    WHERE status IN ('in_progress', 'pending')
    ORDER BY priority ASC, progress DESC
    LIMIT 3
  `, []);

  if (goals.rows.length === 0) return '';

  let snippet = '## 当前 OKR 焦点\n';
  for (const g of goals.rows) {
    snippet += `- ${g.title} (${g.status}, ${g.progress}%)\n`;
  }
  return snippet;
}
```

#### 1.6 替换 thalamus 注入

```javascript
// thalamus.js 修改：
// 删除：独立的 learningBlock + memoryBlock 拼接
// 替换为：
const memoryContext = await buildMemoryContext({
  query: eventDescription,
  mode: determineMode(event),
  tokenBudget: 800,
  pool,
});

const prompt = `${THALAMUS_PROMPT}${memoryContext}\n\n## 当前事件\n${eventJSON}`;
```

#### 1.7 similarity.js 最小改动

```javascript
// vectorSearch() 的 SELECT 加上 created_at
const tasksQuery = `
  SELECT
    t.id, t.title, t.description, t.status, t.metadata, t.project_id,
    t.created_at,  -- 新增
    1 - (t.embedding <=> $1::vector) AS vector_score
  FROM tasks t
  WHERE ...
`;
```

---

### Phase 2: Learnings 向量化（提质）

**核心目标**：让 learnings 从关键词匹配升级为向量搜索，插入统一检索器。

#### 2.1 Migration：learnings 表加 embedding 列

```sql
-- Migration 053: add_learnings_embedding
ALTER TABLE learnings ADD COLUMN IF NOT EXISTS embedding vector(1536);

CREATE INDEX IF NOT EXISTS learnings_embedding_idx
  ON learnings USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);
```

#### 2.2 embedding-service.js 新增 learning 向量化

```javascript
export async function generateLearningEmbeddingAsync(learningId, text) {
  if (!process.env.OPENAI_API_KEY) return;
  try {
    const embedding = await generateEmbedding(text.substring(0, 4000));
    const embStr = `[${embedding.join(',')}]`;
    await pool.query(
      `UPDATE learnings SET embedding = $1::vector WHERE id = $2`,
      [embStr, learningId]
    );
  } catch (_err) {
    // 静默失败，不阻塞主流程
  }
}
```

#### 2.3 learning.js 修改

`recordLearning()` 插入后 fire-and-forget 生成向量：

```javascript
// 在 INSERT 成功后
const text = `${title}\n\n${JSON.stringify(content)}`.substring(0, 4000);
generateLearningEmbeddingAsync(learningId, text);
```

`searchRelevantLearnings()` 升级为向量 + 关键词混合：

```javascript
async function searchRelevantLearnings(context, limit = 10) {
  const queryText = [context.task_type, context.failure_class, context.event_type, context.description]
    .filter(Boolean).join(' ');

  // 优先向量搜索
  const hasEmbeddings = await pool.query(
    `SELECT COUNT(*) FROM learnings WHERE embedding IS NOT NULL`
  );

  let results;
  if (parseInt(hasEmbeddings.rows[0].count) > 0 && process.env.OPENAI_API_KEY) {
    results = await vectorSearchLearnings(pool, queryText, limit * 2);
    // 关键词 boost
    results = results.map(r => ({
      ...r,
      score: r.vector_score + keywordBoost(r, context),
    }));
  } else {
    // fallback: 原有关键词匹配
    results = await keywordSearchLearnings(pool, context, limit);
  }

  return results.sort((a, b) => b.score - a.score).slice(0, limit);
}
```

#### 2.4 Backfill 脚本

```javascript
// scripts/backfill-learning-embeddings.mjs
// 批量处理：每次 50 条，sleep 1s 避免 OpenAI rate limit
// 跳过已有 embedding 的记录
// 失败记录 log 但不中断
```

#### 2.5 插入统一检索器

`memory-retriever.js` 的 `searchSemanticMemory()` 扩展：

```javascript
async function searchSemanticMemory(pool, query, mode) {
  const [taskResults, learningResults] = await Promise.all([
    searchWithVectors(pool, query, { topK: 20 }),
    searchRelevantLearnings({ description: query }, 10),  // Phase 2 新增
  ]);

  return [
    ...taskResults.map(r => ({ ...r, source: 'task' })),
    ...learningResults.map(r => ({ ...r, source: 'learning' })),
  ];
}
```

---

### Phase 3: MMR 精排 + 可观测性（精修）

**核心目标**：提升搜索质量，增加可观测性闭环。

#### 3.1 MMR 重排替代简单去重

```javascript
function mmrRerank(candidates, topK, lambda = 0.7) {
  const selected = [];
  const remaining = [...candidates];

  while (selected.length < topK && remaining.length > 0) {
    let bestIdx = 0;
    let bestMMR = -Infinity;

    for (let i = 0; i < remaining.length; i++) {
      const relevance = remaining[i].finalScore;
      const maxSim = selected.length > 0
        ? Math.max(...selected.map(s => jaccardSimilarity(s.text, remaining[i].text)))
        : 0;
      const mmr = lambda * relevance - (1 - lambda) * maxSim;

      if (mmr > bestMMR) {
        bestMMR = mmr;
        bestIdx = i;
      }
    }

    selected.push(remaining.splice(bestIdx, 1)[0]);
  }

  return selected;
}
```

#### 3.2 Memory Hit Rate 可观测性

每次 thalamus 调用后，记录注入了哪些记忆：

```javascript
// 在 thalamus.js analyzeEvent() 完成后
await pool.query(`
  INSERT INTO cecelia_events (type, payload)
  VALUES ('memory_retrieval', $1)
`, [JSON.stringify({
  query: eventDescription.substring(0, 200),
  mode,
  candidates_count: candidates.length,
  injected_count: finalItems.length,
  injected_sources: finalItems.map(i => i.source),
  token_used: tokenUsed,
  token_budget: tokenBudget,
})]);
```

后续可基于此数据分析：哪些 source 被注入最多、token 利用率、是否有 source 从未被使用。

#### 3.3 Mode Weight 调参

基于 Phase 1-2 运行数据，微调 MODE_WEIGHT 配置。初始值见架构章节，运行后根据 memory_retrieval 事件调整。

---

## 不做的事（明确排除）

| 排除项 | 原因 |
|--------|------|
| memory_entries 三层记忆表 | tasks + learnings + cecelia_events 已覆盖，新表增加复杂度无明确收益 |
| Working Memory 层 | thalamus 无 chain 能力，无数据源。预留接口即可 |
| cecelia_events 向量搜索 | 操作日志不适合语义搜索，时间窗口 + type 过滤足够 |
| BM25 全文搜索 | pgvector + Jaccard 混合已足够 |
| 上下文 Auto-Compaction | 独立 PRD |
| Slot 软配额 + 跨 Slot 借用 | 统一评分 + modeWeight 更简单，效果等价 |

---

## 影响范围

| 文件 | Phase | 改动 | 风险 |
|------|-------|------|------|
| **brain/src/memory-retriever.js** | 1 | **新建**：统一检索入口 | 低（新文件） |
| brain/src/similarity.js:vectorSearch() | 1 | SELECT 加 created_at | 低 |
| brain/src/thalamus.js:analyzeEvent() | 1 | 双注入 → 统一调用 buildMemoryContext | 中 |
| brain/src/thalamus.js:buildMemoryBlock() | 1 | 移除（逻辑迁移到 memory-retriever） | 中 |
| brain/src/learning.js:searchRelevantLearnings() | 2 | 关键词 → 向量+关键词混合 | 中 |
| brain/src/learning.js:recordLearning() | 2 | 新增 fire-and-forget embedding | 低 |
| brain/src/embedding-service.js | 2 | 新增 generateLearningEmbeddingAsync | 低 |
| migration 053 | 2 | learnings 加 embedding 列 + HNSW 索引 | 低 |
| scripts/backfill-learning-embeddings.mjs | 2 | **新建**：backfill 脚本 | 低 |
| brain/src/memory-retriever.js | 3 | 简单去重 → MMR | 低 |
| brain/src/thalamus.js | 3 | 新增 memory_retrieval 事件记录 | 低 |

---

## 验收标准（DoD）

### Phase 1: 统一检索器 + Token 预算

- [ ] `buildMemoryContext()` 返回格式化 context block
- [ ] thalamus 注入 token 数 ≤ 800（默认预算）
- [ ] 时间衰减生效：30 天前任务 score ≈ 原始 50%，90 天前 ≈ 12.5%
- [ ] goals/capabilities 不受时间衰减影响
- [ ] 简单去重生效：top 5 结果两两 Jaccard < 0.8
- [ ] thalamus 正常工作（替换注入后决策不报错）
- [ ] Memory API 响应时间 < 500ms
- [ ] mode 参数影响结果排序（plan 模式 OKR 靠前）

### Phase 2: Learnings 向量化

- [ ] Migration 成功：learnings 表有 embedding 列 + HNSW 索引
- [ ] 新 learning 自动生成 embedding
- [ ] `searchRelevantLearnings({description: "认证失败"})` 找到 "auth error" 相关记录
- [ ] OpenAI API 失败时降级到关键词匹配
- [ ] Backfill 脚本跑完，现有 learnings 补全 embedding
- [ ] learnings 结果出现在 buildMemoryContext 返回中

### Phase 3: MMR + 可观测性

- [ ] MMR 重排替代简单去重
- [ ] memory_retrieval 事件写入 cecelia_events
- [ ] 事件包含：query、mode、candidates_count、injected_count、token_used
- [ ] 所有测试通过

### 回归测试（每个 Phase 都需要）

- [ ] thalamus 决策不报错
- [ ] Memory API 三个端点正常
- [ ] embedding-service fire-and-forget 不阻塞
- [ ] OpenAI API 断开时 graceful fallback

---

## 里程碑

| Phase | 内容 | PR 数 |
|-------|------|-------|
| Phase 1 | 统一检索器 + token 预算 + 时间衰减 + 简单去重 | 1 PR |
| Phase 2 | Learnings 向量化 + backfill + 插入检索器 | 1 PR（含 migration） |
| Phase 3 | MMR 精排 + memory_retrieval 可观测性 | 1 PR |
| 总计 | | 3 PR |
